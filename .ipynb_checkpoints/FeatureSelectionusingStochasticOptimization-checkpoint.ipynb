{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81423131-e489-45b7-89b1-2c7918d94051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.808 (0.031)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=3,\n",
    "    n_informative=2,\n",
    "    n_redundant=1,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# define model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report result\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb452e6-b9d8-4933-a29c-552e6e368462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "False\n",
      "\n",
      ">f([0, 1, 2, 3, 4]) = 0.819667\n",
      "[0, 1, 2, 3]\n",
      "False\n",
      "\n",
      ">f([0, 1, 2, 3]) = 0.820667\n",
      "[0, 1, 2, 4]\n",
      "False\n",
      "\n",
      ">f([0, 1, 2, 4]) = 0.813000\n",
      "[0, 1, 2]\n",
      "False\n",
      "\n",
      ">f([0, 1, 2]) = 0.824333\n",
      "[0, 1, 3, 4]\n",
      "False\n",
      "\n",
      ">f([0, 1, 3, 4]) = 0.821000\n",
      "[0, 1, 3]\n",
      "False\n",
      "\n",
      ">f([0, 1, 3]) = 0.824667\n",
      "[0, 1, 4]\n",
      "False\n",
      "\n",
      ">f([0, 1, 4]) = 0.806333\n",
      "[0, 1]\n",
      "False\n",
      "\n",
      ">f([0, 1]) = 0.821667\n",
      "[0, 2, 3, 4]\n",
      "False\n",
      "\n",
      ">f([0, 2, 3, 4]) = 0.826667\n",
      "[0, 2, 3]\n",
      "False\n",
      "\n",
      ">f([0, 2, 3]) = 0.822667\n",
      "[0, 2, 4]\n",
      "False\n",
      "\n",
      ">f([0, 2, 4]) = 0.825333\n",
      "[0, 2]\n",
      "False\n",
      "\n",
      ">f([0, 2]) = 0.813667\n",
      "[0, 3, 4]\n",
      "False\n",
      "\n",
      ">f([0, 3, 4]) = 0.828000\n",
      "[0, 3]\n",
      "False\n",
      "\n",
      ">f([0, 3]) = 0.817333\n",
      "[0, 4]\n",
      "False\n",
      "\n",
      ">f([0, 4]) = 0.813333\n",
      "[0]\n",
      "False\n",
      "\n",
      ">f([0]) = 0.639333\n",
      "[1, 2, 3, 4]\n",
      "False\n",
      "\n",
      ">f([1, 2, 3, 4]) = 0.825333\n",
      "[1, 2, 3]\n",
      "False\n",
      "\n",
      ">f([1, 2, 3]) = 0.821000\n",
      "[1, 2, 4]\n",
      "False\n",
      "\n",
      ">f([1, 2, 4]) = 0.826667\n",
      "[1, 2]\n",
      "False\n",
      "\n",
      ">f([1, 2]) = 0.821667\n",
      "[1, 3, 4]\n",
      "False\n",
      "\n",
      ">f([1, 3, 4]) = 0.820000\n",
      "[1, 3]\n",
      "False\n",
      "\n",
      ">f([1, 3]) = 0.822667\n",
      "[1, 4]\n",
      "False\n",
      "\n",
      ">f([1, 4]) = 0.808000\n",
      "[1]\n",
      "False\n",
      "\n",
      ">f([1]) = 0.797000\n",
      "[2, 3, 4]\n",
      "False\n",
      "\n",
      ">f([2, 3, 4]) = 0.835000\n",
      "[2, 3]\n",
      "False\n",
      "\n",
      ">f([2, 3]) = 0.754333\n",
      "[2, 4]\n",
      "False\n",
      "\n",
      ">f([2, 4]) = 0.829333\n",
      "[2]\n",
      "False\n",
      "\n",
      ">f([2]) = 0.516667\n",
      "[3, 4]\n",
      "False\n",
      "\n",
      ">f([3, 4]) = 0.826000\n",
      "[3]\n",
      "False\n",
      "\n",
      ">f([3]) = 0.514333\n",
      "[4]\n",
      "False\n",
      "\n",
      ">f([4]) = 0.777667\n",
      "[]\n",
      "False\n",
      "\n",
      "Done!\n",
      "f([2, 3, 4]) = 0.835000\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definir el dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2,\n",
    "                           n_redundant=3, random_state=1)\n",
    "\n",
    "# Determinar el número de columnas (features)\n",
    "n_cols = X.shape[1]\n",
    "best_subset, best_score = None, 0.0\n",
    "\n",
    "# Enumerar todas las combinaciones posibles de features\n",
    "for subset in product([True, False], repeat=n_cols):\n",
    "    # Convertir la combinación booleana a índices de columnas\n",
    "    ix = [i for i, x in enumerate(subset) if x]\n",
    "\n",
    "    # Omitir combinaciones sin columnas seleccionadas\n",
    "    if len(ix) == 0:\n",
    "        continue\n",
    "\n",
    "    # Seleccionar columnas\n",
    "    X_new = X[:, ix]\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = DecisionTreeClassifier()\n",
    "\n",
    "    # Definir el procedimiento de evaluación\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    scores = cross_val_score(model, X_new, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "    # Calcular el promedio de los scores\n",
    "    result = mean(scores)\n",
    "\n",
    "    # Mostrar progreso\n",
    "    print('>f(%s) = %f' % (ix, result))\n",
    "\n",
    "    # Verificar si es el mejor resultado hasta ahora\n",
    "    if best_score is None or result >= best_score:\n",
    "        best_subset, best_score = ix, result\n",
    "\n",
    "# Reportar el mejor subconjunto\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (best_subset, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf91b7e-a161-4ca5-a904-3ac85a362ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.913 (0.001)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Definir dataset con muchas características (500)\n",
    "X, y = make_classification(n_samples=10000, n_features=500, n_informative=10,\n",
    "                           n_redundant=490, random_state=1)\n",
    "\n",
    "# Definir modelo\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Definir procedimiento de evaluación (validación cruzada estratificada)\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# Evaluar el modelo\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Reportar resultados\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382d963a-721a-4816-835f-237012647331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 f(276) = 0.902100\n",
      ">2 f(276) = 0.902100\n",
      ">3 f(277) = 0.902100\n",
      ">4 f(274) = 0.902100\n",
      ">5 f(275) = 0.902100\n",
      ">6 f(276) = 0.902100\n",
      ">7 f(272) = 0.902100\n",
      ">8 f(274) = 0.902100\n",
      ">9 f(275) = 0.902100\n",
      ">10 f(273) = 0.902100\n",
      ">11 f(272) = 0.902100\n",
      ">12 f(277) = 0.902100\n",
      ">13 f(274) = 0.902100\n",
      ">14 f(276) = 0.902100\n",
      ">15 f(273) = 0.902500\n",
      ">16 f(273) = 0.902500\n",
      ">17 f(272) = 0.902500\n",
      ">18 f(274) = 0.904201\n",
      ">19 f(267) = 0.904700\n",
      ">20 f(266) = 0.906300\n",
      ">21 f(264) = 0.911300\n",
      ">22 f(263) = 0.911300\n",
      ">23 f(260) = 0.911300\n",
      ">24 f(264) = 0.911400\n",
      ">25 f(260) = 0.911400\n",
      ">26 f(270) = 0.911400\n",
      ">27 f(265) = 0.911400\n",
      ">28 f(265) = 0.911400\n",
      ">29 f(260) = 0.911400\n",
      ">30 f(266) = 0.911400\n",
      ">31 f(266) = 0.911400\n",
      ">32 f(263) = 0.911400\n",
      ">33 f(269) = 0.911400\n",
      ">34 f(264) = 0.911400\n",
      ">35 f(266) = 0.911400\n",
      ">36 f(262) = 0.911400\n",
      ">37 f(267) = 0.911400\n",
      ">38 f(268) = 0.911400\n",
      ">39 f(262) = 0.911400\n",
      ">40 f(262) = 0.911400\n",
      ">41 f(262) = 0.911400\n",
      ">42 f(263) = 0.911400\n",
      ">43 f(263) = 0.911400\n",
      ">44 f(265) = 0.911400\n",
      ">45 f(259) = 0.911400\n",
      ">46 f(257) = 0.911400\n",
      ">47 f(262) = 0.911400\n",
      ">48 f(268) = 0.911400\n",
      ">49 f(259) = 0.911400\n",
      ">50 f(265) = 0.911400\n",
      ">51 f(259) = 0.911400\n",
      ">52 f(257) = 0.911400\n",
      ">53 f(267) = 0.911400\n",
      ">54 f(263) = 0.911400\n",
      ">55 f(259) = 0.911400\n",
      ">56 f(265) = 0.911400\n",
      ">57 f(261) = 0.911400\n",
      ">58 f(260) = 0.911400\n",
      ">59 f(262) = 0.911400\n",
      ">60 f(262) = 0.911400\n",
      ">61 f(267) = 0.911400\n",
      ">62 f(262) = 0.911400\n",
      ">63 f(259) = 0.911400\n",
      ">64 f(265) = 0.911400\n",
      ">65 f(268) = 0.911400\n",
      ">66 f(263) = 0.911400\n",
      ">67 f(260) = 0.911400\n",
      ">68 f(264) = 0.911400\n",
      ">69 f(259) = 0.911400\n",
      ">70 f(265) = 0.911400\n",
      ">71 f(260) = 0.911400\n",
      ">72 f(265) = 0.911400\n",
      ">73 f(261) = 0.911400\n",
      ">74 f(260) = 0.911400\n",
      ">75 f(263) = 0.911400\n",
      ">76 f(263) = 0.911400\n",
      ">77 f(264) = 0.911400\n",
      ">78 f(262) = 0.911400\n",
      ">79 f(262) = 0.911400\n",
      ">80 f(261) = 0.911400\n",
      ">81 f(261) = 0.911400\n",
      ">82 f(262) = 0.911400\n",
      ">83 f(264) = 0.911400\n",
      ">84 f(258) = 0.911400\n",
      ">85 f(267) = 0.911400\n",
      ">86 f(255) = 0.911400\n",
      ">87 f(264) = 0.911400\n",
      ">88 f(261) = 0.911400\n",
      ">89 f(262) = 0.911400\n",
      ">90 f(255) = 0.911400\n",
      ">91 f(267) = 0.911400\n",
      ">92 f(267) = 0.911400\n",
      ">93 f(263) = 0.911400\n",
      ">94 f(258) = 0.911400\n",
      ">95 f(264) = 0.911400\n",
      ">96 f(263) = 0.911400\n",
      ">97 f(269) = 0.911400\n",
      ">98 f(262) = 0.911400\n",
      ">99 f(259) = 0.911400\n",
      ">100 f(261) = 0.911400\n",
      "Done!\n",
      "Best: f(263) = 0.911400\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy.random import rand, choice\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Función objetivo que evalúa un subconjunto de características\n",
    "def objective(X, y, subset):\n",
    "    # Convertir el subset booleano en índices\n",
    "    ix = [i for i, x in enumerate(subset) if x]\n",
    "\n",
    "    # Si no hay columnas seleccionadas, retornar score 0.0\n",
    "    if len(ix) == 0:\n",
    "        return 0.0, []\n",
    "\n",
    "    # Seleccionar las columnas activas\n",
    "    X_new = X[:, ix]\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = DecisionTreeClassifier()\n",
    "\n",
    "    # Evaluar el modelo con validación cruzada\n",
    "    scores = cross_val_score(model, X_new, y, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "    # Calcular media del score\n",
    "    result = mean(scores)\n",
    "\n",
    "    return result, ix\n",
    "\n",
    "# Operador de mutación\n",
    "def mutate(solution, p_mutate):\n",
    "    # Copiar la solución original\n",
    "    child = solution.copy()\n",
    "\n",
    "    # Aplicar mutación con probabilidad p_mutate a cada bit\n",
    "    for i in range(len(child)):\n",
    "        if rand() < p_mutate:\n",
    "            child[i] = not child[i]\n",
    "    \n",
    "    return child\n",
    "\n",
    "# Algoritmo de búsqueda local tipo Hill Climbing\n",
    "def hillclimbing(X, y, objective, n_iter, p_mutate):\n",
    "    # Generar punto inicial aleatorio\n",
    "    solution = choice([True, False], size=X.shape[1])\n",
    "\n",
    "    # Evaluar punto inicial\n",
    "    solution_eval, ix = objective(X, y, solution)\n",
    "\n",
    "    # Iterar\n",
    "    for i in range(n_iter):\n",
    "        # Generar vecino mutado\n",
    "        candidate = mutate(solution, p_mutate)\n",
    "\n",
    "        # Evaluar vecino\n",
    "        candidate_eval, ix = objective(X, y, candidate)\n",
    "\n",
    "        # Reemplazar si es mejor o igual\n",
    "        if candidate_eval >= solution_eval:\n",
    "            solution, solution_eval = candidate, candidate_eval\n",
    "\n",
    "        # Mostrar progreso\n",
    "        print('>%d f(%d) = %f' % (i+1, len(ix), solution_eval))\n",
    "\n",
    "    return solution, solution_eval\n",
    "\n",
    "# Definir dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=500, n_informative=10,\n",
    "                           n_redundant=490, random_state=1)\n",
    "\n",
    "# Definir número de iteraciones\n",
    "n_iter = 100\n",
    "\n",
    "# Probabilidad de mutación por columna (10 de 500)\n",
    "p_mut = 10.0 / 500.0\n",
    "\n",
    "# Ejecutar búsqueda Hill Climbing\n",
    "subset, score = hillclimbing(X, y, objective, n_iter, p_mut)\n",
    "\n",
    "# Obtener índices seleccionados\n",
    "ix = [i for i, x in enumerate(subset) if x]\n",
    "\n",
    "# Mostrar resultado final\n",
    "print('Done!')\n",
    "print('Best: f(%d) = %f' % (len(ix), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf17723-28cd-4842-bed8-c1e831653279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
